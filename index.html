<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>The Fifth Summer School on Statistical Methods for Linguistics and Psychology</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/lorikeet.jpg">

</head>
<body>

<section class="about">
  <div class="container">
    <h4>Welcome to the Fifth Summer School on Statistical Methods for Linguistics and Psychology, 6-10 September 2021</h4>

    <div class="row">
     </div>

    <br><br><br>
    <div>
    <h3>Application, dates, location</h3>
        <ul>
          <li>Dates: 6-10 September 2021.</li>
          <li>Times: The summer school is being taught completely online, the times will be decided closer to September.</li>
          <li>Location: The course will be taught virtually during this week, using pre-recorded videos, moodle, and Zoom for daily real-time meetings. <strong>For the Introductory courses, the recorded lectures  will be available for free online to everyone (we will decide about the other courses later; watch this space)</strong>.
</li>
          <li><strong>Application period: 16 Jan to 15 April 2021</strong>.  Applications are closed; there were 633 applications. Decisions will be announced by 10th May 2021.</li>
          </ul>
</div>

<div>
     <h3>Brief history of the summer school, and motivation</h3>

The SMLP summer school was started by Shravan Vasishth in 2017, as part of a <a href="https://www.uni-potsdam.de/en/sfb1287/projects/infrastructure-service-training-and-central-projects/project-q.html">methods project</a> funded within the <a href="https://www.uni-potsdam.de/sfb1287/index.html">SFB 1287</a>. The summer school aims to fill a gap in statistics education, specifically within the fields of linguistics and psychology. One goal of the summer school is to provide comprehensive training in the theory and application of statistics, with a special focus on the linear mixed model.  Another major goal is to make Bayesian data analysis a standard part of the toolkit for the linguistics and psychology researcher. Over time, the summer school has evolved to have at least four parallel streams: beginning and advanced courses in frequentist and Bayesian statistics. These may be expanded to more parallel sessions in future editions. We typically admit a total of 120 participants (in 2019, we had some 450 applications). In addition to the all-day courses, we regularly invite speakers to give lectures on important current issues relating to statistics. Previous editions of the summer school: <a href="https://vasishth.github.io/smlp2020/">2020</a>, <a href="https://vasishth.github.io/smlp2019/">2019</a>, <a href="https://vasishth.github.io/SMLP2018/">2018</a>, <a href="https://vasishth.github.io/SMLP2017/">2017</a>.
</div>


<div>
     <h3>Code of conduct</h3>

All participants will be expected to follow the (<a href="http://mc-stan.org/events/stancon2018/stancon-code_of_conduct.html">code of conduct</a>, taken from <a href="http://mc-stan.org/events/stancon2018/">StanCon 2018</a>. In case a participant has any concerns, please contact any of the following instructors: Audrey Bürki, Anna Laurinavichyute, Shravan Vasishth, Bruno Nicenboim, or Reinhold Kliegl. 

</div>

<div>
     <h3>Invited lecturers</h3>

        <ul>
          <li><a href="https://www.gla.ac.uk/researchinstitutes/neurosciencepsychology/staff/lisadebruine/">Lisa DeBruine</a> (co-instructor for Advanced methods in frequentist statistics with Julia)</li>
          <li><a href="http://pages.stat.wisc.edu/~bates/">Douglas Bates</a> (co-instructor for Advanced methods in frequentist statistics with Julia)</li>
          <li><a href="https://phillipalday.com/">Phillip Alday</a> (Advanced methods in frequentist statistics with Julia)</li>
          <li><a href="https://www.jverissimo.net/">João Veríssimo</a> (Foundational methods in frequentist statistics)</li>
             </ul>
</div>


<div>
     <h3>Invited keynote speakers</h3>

<ol>
 <li><a href="http://dora.erbe-matzke.com/">D&oacute;ra Erb&eacute;-Matzke</a>:<br>
<strong>Title</strong>: Flexible cognitive architectures for response inhibition  
<strong>Date</strong>: 7th Sept 2021, 5-6PM.<br>
<strong>Abstract</strong>:
Imagine you driving down the highway stuck behind a slow car. You glance in the rear-view mirror to check if it is safe to overtake, but before you do so, you hear the siren of an ambulance and abort the overtaking manoeuvre. This type of response inhibition—the ability to stop ongoing responses that have become no longer appropriate—is a central component of executive control and is essential for safe and effective interaction with an ever-changing and often unpredictable world. Inhibitory ability is typically quantified by the stop-signal reaction time, the completion time of an inhibitory process triggered by a signal to stop responding. Because stop-signal reaction times cannot be directly observed, they must be inferred based on a model in which independent inhibitory (“stop”') and response (“go”) processes race with each other to control behavior. I review the limitations of the traditional non-parametric race model framework and show that it cannot be used to investigate response inhibition in the full range of situations and paradigms that are relevant to the study of cognitive control. To address this shortcoming, I outline a flexible parametric approach that generalizes the race model to account for aspects of behavior that are characteristics of real-world stopping, such as choice errors, attentional lapses, and the interaction between the stop and go processes. I propose various parametrizations of the framework, ranging from the descriptive ex-Gaussian distribution to a racing diffusion evidence-accumulation architecture, explore the strengths and weaknesses of the different models, and illustrate their utility with clinical and experimental data in choice-based as well as anticipated-response-based paradigms. I end with discussing the potential of this modeling framework to provide a comprehensive account of the mental processes governing behavior in realistically complex situations, and how it may contribute to the prediction of stopping performance in dynamic settings.
</li> 
<li><a href="https://phillipalday.com/">Phillip Alday</a>:<br>

<strong>Title</strong>: Putting the NO in ANOVA: the past, present and future (role) of statistics in linguistics and psychology<br>
<strong>Date</strong>: 9th Sept 2021, 5-6PM.<br>
<strong>Abstract</strong>:
Language science and psychological science have an uneasy relationship with statistics, both as a tool for dealing with data and a tool for building theories. In this talk, I will discuss the historical disappointments and resulting prejudices against statistics as well as critical insights made possible by statistics, before discussing the current state of the field. In particular, I will discuss what modern, computer-age statistical practice -- such as mixed-effects models, Bayesian statistics and machine learning -- has to offer compared to traditional tools and why it's time to use tools that Clark and Cohen could have only dreamed of. In this vein, I will highlight that classical tools were often insufficient even in their heyday and that the increased complexity of modern tools simply reflect the complexity of the underlying data, which we can no longer responsibly ignore. I will focus on modern statistical approaches as a tool for theory building -- both for theories with stochastic and variable components and as a tool for handling messy and variable real-world data -- instead of as an alternative to theory building. For example, I will touch upon how modern approaches allow for an integrative notion of intra- and interindividual variation, thus addressing an inherent data complexity and theoretical concern and allowing for nearly every study to be an individual-differences study. Finally, I will conclude with my vision for (the role of) statistics in the future of psychology and linguistics and provide a few suggestions for how to achieve that vision.
</li>

</ol>

</div>        

<div>
<h3>Curriculum and schedule</h3>

We offer foundational/introductory and advanced courses in Bayesian and frequentist statistics. When applying, participants are expected to choose only one stream.<br>

<!--
<strong>The schedule</strong> for each stream can be downloaded as a pdf file from <a href="https://vasishth.github.io/smlp2020/SMLP2020schedule.pdf">here</a>.
--->

<ul>
<li><strong>Introduction to Bayesian data analysis</strong> (maximum 30 participants). Taught by <a href="https://vasishth.github.io/">Shravan Vasishth</a>, assisted by <a href="https://annlaurin.github.io/">Anna Laurinavichyute</a>, and <a href="https://paulalisson.github.io/">Paula Liss&oacute;n</a></li>

This course is an introduction to Bayesian modeling, oriented towards linguists and psychologists.  Topics to be covered: Introduction to Bayesian data analysis, Linear Modeling, Hierarchical Models. We will cover these topics within the context of an applied Bayesian workflow that includes exploratory data analysis, model fitting, and model checking using simulation. Participants are expected to be familiar with R, and must have some experience in data analysis, particularly with the R library lme4.<br>

<strong>Course Materials</strong>

Textbook draft <a href="https://vasishth.github.io/bayescogsci/">here</a>. We will work through the first five chapters.<br>

Videos from previous editions: available <a href="https://vasishth.github.io/IntroductionBDA/index.html">here</a>.
<br><br>
<li><strong>Advanced Bayesian data analysis</strong> (maximum 30 participants). Taught by <a href="https://bnicenboim.github.io/">Bruno Nicenboim</a>, assisted by <a href="https://sites.google.com/site/himanshuyadavjnu/">Himanshu Yadav</a></li>

This course assumes that participants have some experience in Bayesian modeling already using brms and want to transition to Stan to learn more advanced methods and start building simple computational cognitive models. Participants should have worked through or be familiar with the material in the first five chapters of our book draft: <a href="https://vasishth.github.io/Bayes_CogSci/">Introduction to Bayesian Data Analysis for Cognitive Science</a>. In this course, we will cover Parts III to V of our book draft: model comparison using Bayes factors and k-fold cross validation, introduction and relatively advanced models with Stan, and simple computational cognitive models. 
<br>

<strong>Course Materials</strong>

Textbook draft <a href="https://vasishth.github.io/bayescogsci/">here</a>.<br><br>

<li><strong>Foundational methods in frequentist statistics</strong> (maximum 30 participants). Taught by  <a href="https://www.uni-potsdam.de/en/ling/staff-list/audreybuerki.html">Audrey Buerki</a> and <a href="https://www.jverissimo.net/">João Veríssimo</a>, video recordings by <a href="https://vasishth.github.io">Shravan Vasishth</a>.</li>

Participants will be expected to have used linear mixed models before, to the level of the textbook by <a href="http://www.bodowinter.com/blog/book-release-statistics-for-linguists">Winter (2019, Statistics for Linguists)</a>, and want to acquire a deeper knowledge of frequentist foundations, and understand the linear mixed modeling framework more deeply. Participants are also expected to have fit multiple regressions. We will cover model selection, contrast coding, with a heavy emphasis on simulations to compute power and to understand what the model implies. We will work on (at least some of) the participants' own datasets. <i>This course is not appropriate for researchers new to R or to frequentist statistics</i>.<br>

<strong>Course Materials</strong>

Textbook draft <a href="https://vasishth.github.io/Freq_CogSci/">here</a>.<br>

Videos: available <a href="https://vasishth.github.io/IntroductionStatistics/index.html">here</a>.
<br><br>

<li><strong>Advanced methods in frequentist statistics with Julia</strong> (maximum 30 participants). Taught by <a href="https://phillipalday.com/">Phillip Alday</a>,
<a href="http://pages.stat.wisc.edu/~bates/">Douglas Bates</a>, <a href="https://www.gla.ac.uk/researchinstitutes/neurosciencepsychology/staff/lisadebruine/">Lisa DeBruine</a>, and <a href="https://www.uni-potsdam.de/en/trainingswissenschaft/staff/rkliegl.html">Reinhold Kliegl</a>. </li>

</ul>

Applicants must have experience with linear mixed models and be interested in learning how to carry out such analyses with the <a href="https://github.com/JuliaStats/MixedModels.jl">Julia-based MixedModels.jl package</a>) (i.e., the analogue of the R-based lme4 package). MixedModels.jl has some significant advantages. Some of them are: (a) new and more efficient computational implementation, (b) speed — needed for, e.g.,  complex designs and power simulations, 
(c) more flexibility for selection of parsimonious mixed models, and 
(d) more flexibility in taking into account autocorrelations or other dependencies — typical  EEG-, fMRI-based time series (under development).

We <strong>do not expect</strong> profound knowledge of Julia from participants; the necessary subset of knowledge will be taught on the first day of the course. We do expect a readiness to <a href="https://julialang.org/downloads/">install Julia</a> and the confidence that with some basic instruction participants will be able to adapt prepared Julia scripts for their own data or to adapt some of their own lme4-commands to the equivalent MixedModels.jl-commands. The course will be taught in a hybrid IDE. There is already the option to execute R chunks from within Julia, meaning one needs Julia primarily for execution of MixedModels.jl commands as replacement of lme4. There is also an option to call MixedModels.jl from within R and process the resulting object like an lme4-object. Thus, much of pre- and postprocessing (e.g., data simulation for complex experimental designs; visualization of partial-effect interactions or shrinkage effects) can be carried out in R.
<br>

<strong>Course Materials</strong>

Github repo: <a href="https://github.com/RePsychLing/SMLP2021">here</a>.<br><br>

</div>


<div>
<h3>Fees</h3>

As the course is being carried out virtually, there will be no fee.
<br><br>
</div>


<div>
<h3>Contact details</h3>

For any questions regarding this summer school that have not been addressed on this home page already, please contact <a href="https://vasishth.github.io/">Shravan Vasishth</a>.
<br><br>
</div>

<div>
<h3>Funding</h3>

This summer school is funded by the DFG and is part of the <a href="https://www.uni-potsdam.de/sfb1287/index.html">SFB 1287, “Variability in Language and Its Limits”</a>.
</div>

</div>
<hr/>


</section>

</body>
</html>
